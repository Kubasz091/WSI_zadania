{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing necesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract methods\n",
    "here i create abstract methods for solver, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver(ABC):\n",
    "    \"\"\"A solver. It may be initialized with some hyperparameters.\"\"\"\n",
    "    @abstractmethod\n",
    "    def get_parameters(self):\n",
    "        \"\"\"Returns a dictionary of hyperparameters\"\"\"\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def solve(self, problem, x0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        A method that solves the given problem for given initial solution.\n",
    "        It may accept or require additional parameters.\n",
    "        Returns the solution and may return additional info.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Function(ABC):\n",
    "    \"\"\"A function. It may be initialized with some parameters.\"\"\"\n",
    "    @abstractmethod\n",
    "    def __call__(self, x, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        A method that returns the value of the function at given point.\n",
    "        It may accept or require additional parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def gradient(self, x, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        A method that returns the gradient of the function at given point.\n",
    "        It may accept or require additional parameters.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the purpouse of class AnyFunction is to just hold both the normal function and its gradient in one callable obcect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnyFunction(Function):\n",
    "    def __init__(self, equation, gradient):\n",
    "        self.equation = equation\n",
    "        self.gradient_func = gradient\n",
    "    def __call__(self, x, *args, **kwargs):\n",
    "        return self.equation(x)\n",
    "    def gradient(self, x, *args, **kwargs):\n",
    "        return self.gradient_func(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent solver\n",
    "in the code below i implemtented a simple gradient decent solver that for every point that for a number of iterations it is currently in calculates the gradient of the function and then substracts the gradient*stepsize from the current position\n",
    "\n",
    "- I also experimented with early_stop: when it is active the solver will stop looking for a minimum if the length af the gradient vector is shorter then early_stop value, it is good if the function changes somewhat rapidly in everywhere, rather then in minimum, but very bad when the function has areas where it is still, doesn't change too much, because when the solver gets started in such a point then the solver will immidietly stop solving for minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentSolver(Solver):\n",
    "    def __init__(self, step_size=0.1, max_iter=1000, early_stop=None):\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.stop = early_stop\n",
    "\n",
    "    def set_step_size(self, new_step_size):\n",
    "        self.step_size = new_step_size\n",
    "\n",
    "    def set_early_stop(self, new_early_stop):\n",
    "        self.stop = new_early_stop\n",
    "\n",
    "    def set_max_iter(self, new_max_iter):\n",
    "        self.max_iter = new_max_iter\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {\"step_size\": self.step_size, \"max_iter\": self.max_iter, \"early_stop\": self.stop, \"get_angry\": self.get_angry}\n",
    "\n",
    "    def solve(self, function, x0):\n",
    "        x = x0.copy()\n",
    "\n",
    "        history = []\n",
    "        history.append(x.copy())\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            grad = function.gradient(x)\n",
    "\n",
    "            if self.stop is not None and np.linalg.norm(grad) < self.stop:\n",
    "                break\n",
    "\n",
    "            step = self.step_size * grad\n",
    "\n",
    "            step_lenght = (np.linalg.norm(step))\n",
    "\n",
    "            x -= step\n",
    "            history.append(x.copy())\n",
    "        return x, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difine functions\n",
    "- here i define functions that were given in excersize file, make an object for each of them to be able to hold both the normal functions and their gradients in one object\n",
    "- then i initialize solver object with some arguments, for the first function (1D) it is best to not youse get_angry option as it increases the step_size to infinity, i chose to not hard code any limitations on how big it can get, to not make the solution too complex (also it is just a mode i experimented with, not the original task)\n",
    "- this solver can solve both functions without changing anything in the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(x):\n",
    "    return 2 * x**2 + 3 * x - 1\n",
    "def gradient1(x):\n",
    "    return 4 * x + 3\n",
    "f = AnyFunction(function1, gradient1)\n",
    "\n",
    "def function2(x):\n",
    "    return (1 - 0.6 * np.exp(-x[0]**2 - x[1]**2) - 0.4 * np.exp(-(x[0] + 1.75)**2 - (x[1] - 1)**2))\n",
    "def gradient2(x):\n",
    "    return np.array(\n",
    "        [\n",
    "            1.2 * x[0] * np.exp(-x[0]**2 - x[1]**2) + 0.8 * (x[0] + 1.75) * np.exp(-(x[0] + 1.75)**2 - (x[1] - 1)**2),\n",
    "            1.2 * x[1] * np.exp(-x[0]**2 - x[1]**2) + 0.8 * (x[1] - 1) * np.exp(-(x[0] + 1.75)**2 - (x[1] - 1)**2)\n",
    "        ])\n",
    "g = AnyFunction(function2, gradient2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions visualization\n",
    "- here i plot using matplotlib functions that the solver will later solve (find their minimums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_2D = 3\n",
    "range_1D = 20\n",
    "\n",
    "\n",
    "x = np.linspace(-range_1D, range_1D, 100)\n",
    "y = f(x)\n",
    "fig, ax = plt.subplots()\n",
    "points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "norm = plt.Normalize(y.min(), y.max())\n",
    "lc = mcoll.LineCollection(segments, cmap='coolwarm', norm=norm)\n",
    "lc.set_array(y)\n",
    "lc.set_linewidth(2)\n",
    "line = ax.add_collection(lc)\n",
    "ax.set_title('Plot of f(x)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.grid(True, alpha=0.5)\n",
    "fig.colorbar(line, ax=ax, label='f(x)')\n",
    "ax.set_facecolor('#f0f0f0')\n",
    "plt.xlim(x.min(), x.max())\n",
    "plt.ylim(y.min(), y.max())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(-range_2D, range_2D, 100), np.linspace(-range_2D, range_2D, 100))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(X, Y, g([X, Y]), cmap='coolwarm')\n",
    "plt.title('Plot of g(x, y)')\n",
    "fig.colorbar(surf, ax=ax, label='g(x, y)')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a, b random starting points for each function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10 # number of points for 1D function\n",
    "b = 10 # number of points for 2D function\n",
    "\n",
    "np.random.seed(100) # for reproducibility, comment out for random results\n",
    "\n",
    "random_points_f = np.random.uniform(-range_1D, range_1D, size=(a, 1))\n",
    "random_points_g = np.random.uniform(-range_2D, range_2D, size=(b, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the generated points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = f(random_points_f)\n",
    "plt.scatter(random_points_f, f(random_points_f), c=colors, s=40, cmap='viridis', edgecolors='black')\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.title('Random Points for f(x)')\n",
    "plt.xlabel('X')\n",
    "plt.colorbar(label='f(x)')\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "colors = g(random_points_g.T)\n",
    "plt.scatter(random_points_g[:, 0], random_points_g[:, 1], c=colors, s=40, cmap='viridis', edgecolors='black')\n",
    "plt.title('Random Points for g(x, y)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar(label='g(x, y)')\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions that will solve the functions for minimums for each step size and each start point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_2D(function, no_step_sizes, range_of_step_sizes, random_points, solver, filename):\n",
    "    n = no_step_sizes\n",
    "    m = len(random_points)\n",
    "\n",
    "    step_sizes = np.random.uniform(range_of_step_sizes[0], range_of_step_sizes[1], n)\n",
    "    step_sizes = np.sort(step_sizes)\n",
    "\n",
    "    x = np.linspace(-3, 3, 100)\n",
    "    y = np.linspace(-3, 3, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = function([X, Y])\n",
    "\n",
    "    fig, axs = plt.subplots(n, m, figsize=(10*m, 10*n), subplot_kw={'projection': '3d'})\n",
    "    for i, step_size in enumerate(step_sizes):\n",
    "        solver.set_step_size(step_size)\n",
    "        for j, point in enumerate(random_points):\n",
    "            _, data = solver.solve(function, point)\n",
    "\n",
    "            points = np.array(data)\n",
    "            points_Z = function([points[:, 0], points[:, 1]])\n",
    "\n",
    "            ax = axs[i, j]\n",
    "            ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.5)\n",
    "            ax.plot(points[:, 0], points[:, 1], points_Z, color='blue')\n",
    "\n",
    "            ax.scatter(points[:, 0], points[:, 1], points_Z, color='red', s=10, alpha=0.5)\n",
    "            ax.scatter(points[0, 0], points[0, 1], points_Z[0], color='green', s=100)\n",
    "            ax.scatter(points[-1, 0], points[-1, 1], points_Z[-1], color='black', s=100)\n",
    "            ax.set_title(f'Step size: {step_size:.3f}, Starting point: {point}, number of iterations: {len(data)}')\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_1D(function, no_step_sizes, range_of_step_sizes, random_points, solver, filename):\n",
    "    n = no_step_sizes\n",
    "    m = len(random_points)\n",
    "\n",
    "    step_sizes = np.random.uniform(range_of_step_sizes[0], range_of_step_sizes[1], n)\n",
    "    step_sizes = np.sort(step_sizes)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(n, m, figsize=(10*m, 10*n))\n",
    "    for i, step_size in enumerate(step_sizes):\n",
    "        solver.set_step_size(step_size)\n",
    "        for j, point in enumerate(random_points):\n",
    "            _, data = solver.solve(function, point)\n",
    "\n",
    "            points = np.array(data)\n",
    "            points_y = function(points)\n",
    "\n",
    "            x_max = max(points)\n",
    "\n",
    "            if x_max < range_1D:\n",
    "                x_max = range_1D\n",
    "\n",
    "            x = np.linspace(-x_max, x_max, 100)\n",
    "            y = function(x)\n",
    "\n",
    "            ax = axs[i, j]\n",
    "            ax.plot(x, y, color='blue', alpha=0.5, linewidth=5)\n",
    "            ax.plot(points, points_y, color='red', linestyle='--')\n",
    "\n",
    "            ax.scatter(points, points_y, color='red', s=10, alpha=0.5)\n",
    "            ax.scatter(points[0], points_y[0], color='green', s=100)\n",
    "            ax.scatter(points[-1], points_y[-1], color='black', s=100)\n",
    "            ax.set_title(f'Step size: {step_size:.3f}, Starting point: {point}, number of iterations: {len(data)}')\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the plot files\n",
    "- I made a dicision to not display the results in the notebook as the generated file can be quite big, so it is saved in a currents working category with the name specified by filename\n",
    "- the plots can be generated using code below (it is best to not increase the no_step_sizes or number of random points as it will take a long time to generate and the file will be very big in size so depends on the computer it can be even impossible to display)\n",
    "\n",
    "## for 1D function\n",
    "- it can be noticed that after step_size value exceeds about 0.5 algorythm doesn't find a minimum, but just explodes in value\n",
    "- also I noticed that for such a simple function a step_size of about 0.3 solves the funciton is the least ammount of iterations when early_stop is active\n",
    "- but the most reliable from the plots seemes to be 0,1 a good deal beetwen small no_of_itrerations and not too big steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = GradientDescentSolver(step_size=0.1, max_iter=100, early_stop=1e-4)\n",
    "plot_and_save_1D(function=f, no_step_sizes=20, range_of_step_sizes=[0.001, 1], random_points=random_points_f, solver=solver, filename='gradient_descent_1D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for 2D function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with early stop the functiton sometimes saves some iterations that wouldn't imrpove minimum by a big margin, but if the point is in a still region of the function it can terminate solve procces right away, making it impossible for the algorythm to ever find any minimum (it can be mitigated by setting early stop to about 1e-6 but then it often doesn't stop even after algoryth has reached minimum)\n",
    "- for this reason i also generated a file wihout early_stopping, but in it i only tested the range of [0, 1] step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with early stop\n",
    "solver.set_max_iter(1000)\n",
    "\n",
    "plot_and_save_2D(function=g, no_step_sizes=20, range_of_step_sizes=[0.01, 2], random_points=random_points_g, solver=solver, filename='gradient_descent_2D_with_early_stop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without early stop\n",
    "solver.set_early_stop(None)\n",
    "\n",
    "plot_and_save_2D(function=g, no_step_sizes=10, range_of_step_sizes=[0.01, 1], random_points=random_points_g, solver=solver, filename='gradient_descent_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it can be noticed that bigger step sizes with early_stopping can make the algorythm find the minimum faster, but too big (more then 1,5) can make it never find a minimum becouse of too large step size\n",
    "- i would say that for the 2D funciton a step size of about 0,5 seems the best at solving the function reliably and for most points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
